{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> from keras.preprocessing.image import ImageDataGenerator  \n",
    "> train_datagen=ImageDataGenerator(rescale=1./255,shear_range=0.2,zoom_r\n",
    "> ange=0.2,horizontal_flip=True)  \n",
    "> test_datagen=ImageDataGenerator(rescale=1)\n",
    ">\n",
    "> x_train=train_datagen.flow_from_directory(r'/content/drive/MyDrive/\n",
    "> DataSet/Dataset Plant  \n",
    "> Disease/fruit-dataset/fruit-dataset/test',target_size=(128,128),batch\\_\n",
    "> size=2,class_mode='categorical')  \n",
    "> x_test=test_datagen.flow_from_directory(r'/content/drive/MyDrive/DataS\n",
    "> et/Dataset Plant  \n",
    "> Disease/fruit-dataset/fruit-dataset/train',target_size=(128,128),batch\n",
    "> \\_size=2,class_mode='categorical')\n",
    ">\n",
    "> Found 1686 images belonging to 6 classes. Found 5384 images belonging\n",
    "> to 6 classes.\n",
    ">\n",
    "> 1\\. import the libraries\n",
    ">\n",
    "> from keras.models import Sequential from keras.layers import Dense  \n",
    "> from keras.layers import Convolution2D from keras.layers import\n",
    "> MaxPooling2D from keras.layers import Flatten\n",
    ">\n",
    "> 1\\. initializing the model\n",
    ">\n",
    "> model=Sequential()\n",
    ">\n",
    "> 1\\. Add CNN layers\n",
    ">\n",
    "> model.add(Convolution2D(32,  \n",
    "> (3,3),input_shape=(128,128,3),activation='relu'))\n",
    ">\n",
    "> model.add(MaxPooling2D(pool_size=(2,2)))\n",
    ">\n",
    "> model.add(Flatten())\n",
    ">\n",
    "> 1\\. Add dense layer\n",
    ">\n",
    "> model.add(Dense(units=40,kernel_initializer='uniform',activation='relu\n",
    "> '))\n",
    ">\n",
    "> model.add(Dense(units=20,kernel_initializer='random_uniform',activatio\n",
    "> n='relu'))\n",
    ">\n",
    "> model.add(Dense(units=6,kernel_initializer='random_uniform',activation\n",
    "> ='softmax'))\n",
    ">\n",
    "> 1\\. Train and save the model\n",
    ">\n",
    "> model.compile(loss='categorical_crossentropy',optimizer=\"adam\",metrics\n",
    "> =\\[\"accuracy\"\\])\n",
    ">\n",
    "> model.fit(x_train,steps_per_epoch=89,epochs=20,validation_data=x_test,\n",
    "> validation_steps=27)\n",
    ">\n",
    "> Epoch 1/20  \n",
    "> 89/89 \\[==============================\\] - 146s 2s/step - loss: 1.6616\n",
    "> accuracy: 0.3764 - val_loss: 203.1930 - val_accuracy: 0.2963  \n",
    "> Epoch 2/20  \n",
    "> 89/89 \\[==============================\\] - 129s 1s/step - loss: 1.7158\n",
    "> accuracy: 0.2697 - val_loss: 22.3784 - val_accuracy: 0.2778  \n",
    "> Epoch 3/20  \n",
    "> 89/89 \\[==============================\\] - 125s 1s/step - loss: 1.6271\n",
    "> accuracy: 0.3258 - val_loss: 163.5451 - val_accuracy: 0.3333  \n",
    "> Epoch 4/20  \n",
    "> 89/89 \\[==============================\\] - 112s 1s/step - loss: 1.3890\n",
    "> accuracy: 0.4888 - val_loss: 88.6855 - val_accuracy: 0.5926  \n",
    "> Epoch 5/20  \n",
    "> 89/89 \\[==============================\\] - 112s 1s/step - loss: 0.9276\n",
    "> accuracy: 0.6236 - val_loss: 164.1111 - val_accuracy: 0.6667  \n",
    "> Epoch 6/20  \n",
    "> 89/89 \\[==============================\\] - 105s 1s/step - loss: 0.7846\n",
    "> accuracy: 0.6798 - val_loss: 71.4850 - val_accuracy: 0.6481  \n",
    "> Epoch 7/20  \n",
    "> 89/89 \\[==============================\\] - 99s 1s/step - loss: 0.7925\n",
    "> - accuracy: 0.7135 - val_loss: 102.9553 - val_accuracy: 0.5926  \n",
    "> Epoch 8/20  \n",
    "> 89/89 \\[==============================\\] - 98s 1s/step - loss: 0.7527\n",
    "> - accuracy: 0.7135 - val_loss: 560.5753 - val_accuracy: 0.5000  \n",
    "> Epoch 9/20  \n",
    "> 89/89 \\[==============================\\] - 92s 1s/step - loss: 0.7694\n",
    "> - accuracy: 0.6966 - val_loss: 69.2323 - val_accuracy: 0.7963  \n",
    "> Epoch 10/20  \n",
    "> 89/89 \\[==============================\\] - 95s 1s/step - loss: 0.6303\n",
    "> - accuracy: 0.8090 - val_loss: 126.6944 - val_accuracy: 0.6296  \n",
    "> Epoch 11/20  \n",
    "> 89/89 \\[==============================\\] - 88s 978ms/step - loss:\n",
    "> 0.6382- accuracy: 0.7584 - val_loss: 65.5593 - val_accuracy: 0.7593  \n",
    "> Epoch 12/20  \n",
    "> 89/89 \\[==============================\\] - 87s 980ms/step - loss:\n",
    "> 0.6182- accuracy: 0.7865 - val_loss: 86.7426 - val_accuracy: 0.6667  \n",
    "> Epoch 13/20  \n",
    "> 89/89 \\[==============================\\] - 84s 938ms/step - loss:\n",
    "> 0.5206- accuracy: 0.8034 - val_loss: 43.7637 - val_accuracy: 0.8333  \n",
    "> Epoch 14/20  \n",
    "> 89/89 \\[==============================\\] - 86s 976ms/step - loss:\n",
    "> 0.5636- accuracy: 0.8202 - val_loss: 112.9079 - val_accuracy: 0.7037  \n",
    "> Epoch 15/20  \n",
    "> 89/89 \\[==============================\\] - 83s 937ms/step - loss:\n",
    "> 0.5015- accuracy: 0.8315 - val_loss: 81.1166 - val_accuracy: 0.7407  \n",
    "> Epoch 16/20  \n",
    "> 89/89 \\[==============================\\] - 84s 943ms/step - loss:\n",
    "> 0.4755- accuracy: 0.8315 - val_loss: 97.4727 - val_accuracy: 0.7593  \n",
    "> Epoch 17/20  \n",
    "> 89/89 \\[==============================\\] - 85s 965ms/step - loss:\n",
    "> 0.4559\n",
    ">\n",
    "> \\- accuracy: 0.8427 - val_loss: 88.8596 - val_accuracy: 0.7407  \n",
    "> Epoch 18/20  \n",
    "> 89/89 \\[==============================\\] - 82s 923ms/step - loss:\n",
    "> 0.3686- accuracy: 0.8596 - val_loss: 107.9981 - val_accuracy: 0.7222  \n",
    "> Epoch 19/20  \n",
    "> 89/89 \\[==============================\\] - 80s 901ms/step - loss:\n",
    "> 0.4244- accuracy: 0.8764 - val_loss: 34.6990 - val_accuracy: 0.8704  \n",
    "> Epoch 20/20  \n",
    "> 89/89 \\[==============================\\] - 80s 897ms/step - loss:\n",
    "> 0.5965- accuracy: 0.7809 - val_loss: 64.9681 - val_accuracy: 0.7222\n",
    ">\n",
    "> \\<keras.callbacks.History at 0x7f2f0fc41d90\\>\n",
    ">\n",
    "> model.save('fruit.h5')\n",
    ">\n",
    "> model.summary()\n",
    ">\n",
    "> Model: \"sequential\"  \n",
    "> \\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\n",
    "> Layer (type) Output Shape Param \\#\n",
    "> =================================================================\n",
    "> conv2d (Conv2D) (None, 126, 126, 32) 896 max_pooling2d (MaxPooling2D\n",
    "> (None, 63, 63, 32) 0  \n",
    "> )  \n",
    "> flatten (Flatten) (None, 127008) 0  \n",
    "> dense (Dense) (None, 300) 38102700 dense_1 (Dense) (None, 40) 12040\n",
    "> dense_2 (Dense) (None, 20) 820 dense_3 (Dense) (None, 6) 126\n",
    "> =================================================================\n",
    "> Total params: 38,116,582  \n",
    "> Trainable params: 38,116,582  \n",
    "> Non-trainable params: 0  \n",
    "> \\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_"
   ]
  }
 ],
 "nbformat": 4,
 "nbformat_minor": 5,
 "metadata": {}
}
